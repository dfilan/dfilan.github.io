<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Building a search engine for data structures</title>
  <meta name="description" content="Today I presented at Scala By The Bay about my project to build a search engine for data structures. I’ve deployed the project at ds.shlegeris.com; you can p...">


  <link rel="stylesheet" href="/stylesheets/styles.css">
  <link rel="stylesheet" href="/stylesheets/pygment_trac.css">
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  <link rel="canonical" href="http://danielfilan.com//2016/11/13/ds.html">
  <link rel="alternate" type="application/rss+xml" title="Daniel Filan" href="http://danielfilan.com//feed.xml">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$$', '$$'] ],
        displayMath: [ ['$^$', '$^$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
  </script>
  <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>


  <body>

    

    <div class="wrapper">
  <header>
  <h1><a href="/">Daniel Filan</a></h1>
  <img src="https://scontent-sjc2-1.xx.fbcdn.net/v/t1.0-9/11659278_10202944584654914_2762452412152680044_n.jpg?oh=f017f593bd04d84d5de68bb00a736ddf&oe=58486651"/>
  <ul>
    <li><a href="/pdfs/cv.pdf">CV</a></li>
    <li><a href="mailto:df@danielfilan.com">email</a></li>
    <li><a href="/daniel_filan_public_key.asc">PGP public key</li>
    <li><a href="https://github.com/dfilan">github</a></li>
    <li><a href="/posts">blog</a></li>
  </ul>
</header>


  <section>
    <h2>Building a search engine for data structures</h2>
    <p>Today I <a href="https://scalaebythebay2016.sched.org/event/7iUk/automatic-composition-of-fast-data-structures">presented at Scala By The Bay</a> about my project to build a search engine for data structures. I’ve deployed the project at <a href="http://ds.shlegeris.com">ds.shlegeris.com</a>; you can play with it there. You can also read the source code <a href="https://github.com/bshlgrs/data-structure-composer">on Github</a>.</p>

<p>This blog post is a more detailed version of the talk I gave today.</p>

<h2 id="a-search-engine-for-data-structures">A search engine for data structures</h2>

<p>A data structure is a way of organizing data to efficiently support a particular API. So a data structure search engine is a program which takes an API and returns an efficient implementation.</p>

<p>Let’s look at some examples of queries that the search engine is able to support. Here’s one from Cracking the Coding Interview:</p>

<p><img class="shadow-img" src="/img/sbtb/ctci.png" /></p>

<p>You can see the answer my software finds <a href="http://ds.shlegeris.com/#getLast,deleteLast!,insertLast!,getMinimum">here</a>.</p>

<p>Here’s one from Quora:</p>

<p><img class="shadow-img" src="/img/sbtb/quora1.png" /></p>

<p>And <a href="http://ds.shlegeris.com/#getMinimum,getMaximum,deleteMaximum!,deleteMinimum!,deleteFirstNodeWithValue!,insertAnywhere!">here’s my answer</a>.</p>

<p>Here’s a third Quora question:</p>

<p><img class="shadow-img" src="/img/sbtb/quora2.png" /></p>

<p><a href="http://ds.shlegeris.com/#getFirst,deleteFirst!,insertLast!,deleteAtIndex!">And my answer</a>.</p>

<p>The pattern here is that we are being asked to choose a fast data structure to support a given set of methods. I’m going to call that set of methods an <a href="https://en.wikipedia.org/wiki/Abstract_data_type">abstract data type</a>, or ADT for short.</p>

<h2 id="implementation">Implementation</h2>

<p>The whole project is built around a bank of knowledge about data structures and the relationships between different methods.</p>

<p>The core algorithm is something like the following pseudocode:</p>

<div class="language-scala highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="n">chooseFastDataStructuresForAdt</span><span class="o">(</span><span class="n">adt</span><span class="k">:</span> <span class="kt">AbstractDataType</span><span class="o">)</span><span class="k">:</span> <span class="kt">Set</span><span class="o">[</span><span class="kt">DataStructureChoice</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">options</span><span class="k">:</span> <span class="kt">Set</span><span class="o">[</span><span class="kt">DataStructureChoice</span><span class="o">]</span> <span class="k">=</span>
    <span class="n">allDataStructures</span><span class="o">.</span><span class="n">subsets</span>
                     <span class="o">.</span><span class="n">map</span><span class="o">((</span><span class="n">subset</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">findAllTimes</span><span class="o">(</span><span class="n">subset</span><span class="o">,</span> <span class="n">adt</span><span class="o">))</span>

  <span class="n">adt</span><span class="o">.</span><span class="n">pickBestCompositeDataStructures</span><span class="o">(</span><span class="n">options</span><span class="o">)</span>
<span class="o">}</span>
</code></pre>
</div>

<p>So we compute the times taken for all the methods by each possible composite data structure. Then we choose the best data structures for our use case.</p>

<!--
<p>
### Aside: Dominance frontiers

One type that I use a lot in this code is what I'm calling a `DominanceFrontier`, for lack of a better name. A dominance frontier is a set of items `A` with a partial ordering on them, such that no item is strictly dominated by any other. For example, in the type of algebraic expressions with free variables $$x$$ and $$y$$ where our partial ordering is based on their asymptotic growth, I might have the set $$\{x + y, x \log(x), y^2\}$$, because no element is strictly less than any other. However, I couldn't add $$\{x\}$$ to that set, because it's not asymptotically greater than $$\{x + y\}$$.

`DominanceFrontier` is a monad over the category of partially ordered Scala objects (if you count Set as a monad). It's a super useful abstraction over the idea of doing a search for the optimal solutions for some problem, and wanting to maintain all plausible subsolutions along the way.
</p> -->

<h3 id="inference-on-method-implementations">Inference on method implementations</h3>

<p>To do this kind of inference, we need to be able to evaluate the runtimes of all methods of a particular composite data structure. Let’s look at how that works.</p>

<p>Throughout this whole thing I’m going to assume we’re talking about methods on an ordered list.</p>

<p>We need to talk about lots of different methods, like <code class="highlighter-rouge">getFirst</code>, <code class="highlighter-rouge">getNext</code>, <code class="highlighter-rouge">getByIndex</code>. These are redundant on purpose. In an array, it’s natural to define <code class="highlighter-rouge">getByIndex</code> and derive <code class="highlighter-rouge">getFirst</code> and <code class="highlighter-rouge">getNext</code> from that. In a linked list, the other way round is nicer.</p>

<p>We will describe the read methods of an ArrayList like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ds ArrayList {
  getByIndex &lt;- 1
}
</code></pre>
</div>

<p>And a linked list will look like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ds LinkedList {
  getNext &lt;- 1
  getFirst &lt;- 1
}
</code></pre>
</div>

<p>The central relationship that we care about is how implementations can be used to implement other things. Let’s make some rules like that:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>getByIndex &lt;- getFirst + n * getNext
getFirst &lt;- getByIndex
getNext &lt;- getByIndex
</code></pre>
</div>

<p>So you can implement <code class="highlighter-rouge">getByIndex</code> with O(1) calls to <code class="highlighter-rouge">getFirst</code> and O(n) calls to <code class="highlighter-rouge">getNext</code>. You can also implement <code class="highlighter-rouge">getFirst</code> or <code class="highlighter-rouge">getNext</code> with O(1) calls to <code class="highlighter-rouge">getByIndex</code>.</p>

<p>Facts of this type are called ‘implementations’ in my system; they have the class <code class="highlighter-rouge">Impl</code>. Implementations can either belong to data structures, like <code class="highlighter-rouge">getByIndex &lt;- 1</code> above, or they can be universally true, like <code class="highlighter-rouge">getByIndex &lt;- getFirst + n * getNext</code>.</p>

<p>There’s a useful distinction between implementations with free variables (like <code class="highlighter-rouge">f &lt;- g</code>) and those without (<code class="highlighter-rouge">f &lt;- 1</code>). I call the former type free and the latter type bound. Bound implementations are a subset of free implementations. I represent these with the classes FreeImpl and BoundImpl. (These names aren’t great, I’d be happy to hear suggestions for better ones. In lambda calculus a term with no free variables is called a combinator, but almost no-one would actually think that’s an intuitive term for what I’m talking about here.)</p>

<h5 id="parameterization">Parameterization</h5>

<p>Additional complexity comes from the fact that implementations can be parameterized, and can have conditions attached to their parameters. For example, the method <code class="highlighter-rouge">reduce[f]</code> is parameterized by the function it’s reducing. The difference between a method being parameterized and it taking an argument is that the parameter must be known at the time of data structure initialization.</p>

<p>For example, if I want to have a list which maintains its sum, I can just store the sum as an Int somewhere, and add new values to my sum as they’re inserted and subtract them as they’re removed. This is possible because <code class="highlighter-rouge">+</code> is invertible. So I want to be able to write down a data structure for maintaining this kind of reduction. (simplified from <a href="https://github.com/bshlgrs/data-structure-composer/blob/d18a104400e214e589cefb72f8d466b97ae44c5f/data/data_structures/InvertibleReductionMemoizer.txt">here</a>)</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ds InvertibleReductionMemoizer[f] if f.invertible {
    reduce[f] &lt;- 1
    insertLast! &lt;- 1
    deleteLast! &lt;- 1

    // you can do this anywhere if the
    insertAtIndex! if f.commutative &lt;- 1
    updateNode! if f.commutative &lt;- 1
    deleteNode! if f.commutative &lt;- 1
}
</code></pre>
</div>

<p>This data structure lets you push and pop values and maintains the reduction for any invertible function <code class="highlighter-rouge">f</code>. In addition, if <code class="highlighter-rouge">f</code> is commutative, you’re allowed to do random modifications to the list.</p>

<p>These constraints need to be propogated through the code. For example, my code contains these implementations:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>getMinimum &lt;- getFirstBy[valueOrdering]
getFirstBy[f] &lt;- reduce[_{commutative, idempotent} &lt;- f]
</code></pre>
</div>

<p>The <code class="highlighter-rouge">getFirstBy</code> implementation means that you can implement <code class="highlighter-rouge">getFirstBy[f]</code> by using <code class="highlighter-rouge">reduce</code> with a parameter which is commutative and idempotent, and which requires calling <code class="highlighter-rouge">f</code> every time it is called.</p>

<p>We still have the distinction between free and bound implementations: <code class="highlighter-rouge">f[x] &lt;- x</code> is bound and <code class="highlighter-rouge">f[y] &lt;- z</code> is free.</p>

<h4 id="searching-through-implementations">Searching through implementations</h4>

<p>To search for method times for a given data structure, we start out by taking the union of all the implementations for a data structure and all the universal implementations, so in the case of the LinkedList above we have</p>

<div class="highlighter-rouge"><pre class="highlight"><code>getNext &lt;- 1
getFirst &lt;- 1
getByIndex &lt;- getFirst + n * getNext
getFirst &lt;- getByIndex
getNext &lt;- getByIndex
reduce[f] &lt;- getFirst + n * getNext + n * f
</code></pre>
</div>

<p>We want to end up with a map from methods to their final cost. To do this, we will basically graph search over our <code class="highlighter-rouge">Set[Impl]</code>. The code for that search looks something like this (real version <a href="https://github.com/bshlgrs/data-structure-composer/blob/cf5b29d5610cc7633ac86f40dabe697afef2f206/src/main/scala/implementationSearcher/Searcher.scala#L23-L68">here</a>):</p>

<div class="language-scala highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="n">getAllTimes</span><span class="o">(</span><span class="n">implementations</span><span class="k">:</span> <span class="kt">Set</span><span class="o">[</span><span class="kt">Impl</span><span class="o">])</span><span class="k">:</span> <span class="kt">MethodTimes</span> <span class="o">=</span> <span class="o">{</span>
  <span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MethodTimes</span><span class="o">()</span>
  <span class="k">val</span> <span class="n">queue</span> <span class="k">=</span> <span class="n">mutable</span><span class="o">.</span><span class="nc">PriorityQueue</span><span class="o">[</span><span class="kt">BoundImpl</span><span class="o">](</span><span class="n">implementations</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">hasNoFreeVariables</span><span class="o">))</span>

  <span class="k">while</span> <span class="o">(</span><span class="n">queue</span><span class="o">.</span><span class="n">nonEmpty</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">impl</span> <span class="k">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">pop</span><span class="o">()</span>

    <span class="c1">// add impl to the result if it isn't already in there
</span>    <span class="k">if</span> <span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="n">implIsUseful</span><span class="o">(</span><span class="n">impl</span><span class="o">))</span> <span class="o">{</span>
      <span class="n">result</span><span class="o">.</span><span class="n">addImpl</span><span class="o">(</span><span class="n">impl</span><span class="o">)</span>

      <span class="n">implementations</span><span class="o">.</span><span class="n">foreach</span><span class="o">((</span><span class="n">neighbor</span><span class="k">:</span> <span class="kt">Impl</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">neighbor</span><span class="o">.</span><span class="n">uses</span><span class="o">(</span><span class="n">impl</span><span class="o">.</span><span class="n">methodProvided</span><span class="o">))</span> <span class="o">{</span>
          <span class="c1">// Take the neighbor, like `getByIndex &lt;- getFirst + n * getNext`
</span>          <span class="c1">// and see if it can be used -- in this case, seeing whether you have
</span>          <span class="c1">// a time for both getFirst and getNext. If so, push it to the queue.
</span>
          <span class="c1">// this can return multiple things in the case of
</span>          <span class="c1">// parameterized implementations
</span>          <span class="n">neighbor</span><span class="o">.</span><span class="n">bind</span><span class="o">(</span><span class="n">result</span><span class="o">).</span><span class="n">map</span><span class="o">((</span><span class="n">boundNeighbor</span><span class="k">:</span> <span class="kt">BoundImpl</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
            <span class="k">if</span> <span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="n">implIsUseful</span><span class="o">(</span><span class="n">boundNeighbor</span><span class="o">))</span> <span class="o">{</span>
              <span class="n">queue</span><span class="o">.</span><span class="n">push</span><span class="o">(</span><span class="n">boundNeighbor</span><span class="o">)</span>
            <span class="o">}</span>
          <span class="o">})</span>
        <span class="o">}</span>
      <span class="o">})</span>
    <span class="o">}</span>
  <span class="o">}</span>

  <span class="n">result</span>
<span class="o">}</span>
</code></pre>
</div>

<p>The <code class="highlighter-rouge">bind</code> method of Impl only returns a non-empty set if it can substitute out all the free variables in the right hand side of the Impl. For example, <code class="highlighter-rouge">bind</code> will return <code class="highlighter-rouge">getByIndex &lt;- n</code> when called on <code class="highlighter-rouge">getByIndex &lt;- getFirst + n * getNext</code> with a result set containing <code class="highlighter-rouge">getFirst &lt;- 1</code> and <code class="highlighter-rouge">getNext &lt;- 1</code>. But it will never return something like <code class="highlighter-rouge">getByIndex &lt;- getFirst + n</code>.</p>

<p>For non-parameterized implementations, there is always a fastest way of doing them. This isn’t true for parameterized implementations, because different implementations might have different conditions and costs which don’t strictly dominate each other. For example, the implementations</p>

<div class="highlighter-rouge"><pre class="highlight"><code>foo[f] if f.bar &lt;- 1
foo[f] if f.baz &lt;- 1
foo[f] &lt;- n
foo[f] &lt;- f
</code></pre>
</div>

<p>are all useful in different situations, so we want to return all of them.</p>

<p>(In practice, I haven’t needed to use this expressiveness very often, and it does make my code much more complicated. So I think I might regret adding it. I’m not sure yet. Certainly it’s useful to be able to pass conditions around, I’m not so sure it’s important to be able to refer to bound variables in the RHS of your Impl.)</p>

<h4 id="composing-data-structures">Composing data structures</h4>

<p>When you have a composite data structure, you only have to run your read methods on one of the data structures, but you have to run your write methods on all of them.</p>

<p>However, the write methods of one data structure can rely on read methods of another. Consider again the single Int which we can use to maintain the sum of a list. On its own, it doesn’t support deletion methods like <code class="highlighter-rouge">deleteLast</code>. But if it is paired with an ArrayList, it can use the <code class="highlighter-rouge">getLast</code> method of the ArrayList to find out what it needs to subtract.</p>

<p>So we end up with code approxiately like this (<a href="https://github.com/bshlgrs/data-structure-composer/blob/d18a104400e214e589cefb72f8d466b97ae44c5f/src/main/scala/implementationSearcher/Searcher.scala#L83-L103">real version here</a>):</p>

<div class="language-scala highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="n">getAllTimesForDataStructures</span><span class="o">(</span><span class="n">dataStructures</span><span class="k">:</span> <span class="kt">Set</span><span class="o">[</span><span class="kt">DataStructure</span><span class="o">])</span><span class="k">:</span> <span class="kt">MethodTimes</span> <span class="o">=</span> <span class="o">{</span>
  <span class="c1">// for the read methods, union everything provided by the data structures
</span>  <span class="c1">// with the defaultReadImpls, then search for times with it
</span>  <span class="k">val</span> <span class="n">allReadTimes</span> <span class="k">=</span> <span class="n">getAllTimes</span><span class="o">(</span><span class="n">dataStructures</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">readImpls</span><span class="o">)</span> <span class="o">++</span> <span class="n">defaultReadImpls</span><span class="o">)</span>

  <span class="c1">// calculate all write times separately
</span>  <span class="k">val</span> <span class="n">writeTimesForDataStructures</span> <span class="k">=</span> <span class="n">dataStructures</span><span class="o">.</span><span class="n">flatMap</span><span class="o">((</span><span class="n">ds</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="n">getAllTimes</span><span class="o">(</span><span class="n">ds</span><span class="o">.</span><span class="n">writeImpls</span> <span class="o">++</span> <span class="n">allReadTimes</span><span class="o">)</span>
  <span class="o">})</span>

  <span class="c1">// add them to each other
</span>  <span class="k">val</span> <span class="n">overallWriteTimes</span> <span class="k">=</span> <span class="n">writeTimesForDataStructures</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reduce</span><span class="o">(</span><span class="k">_</span> <span class="n">leastUpperBound</span> <span class="k">_</span><span class="o">)</span>

  <span class="n">allReadTimes</span> <span class="o">++</span> <span class="n">overallWriteTimes</span>
<span class="o">}</span>
</code></pre>
</div>

<p>And now we can find optimally fast composite data structures!</p>

<p>Parameterizated data structures work very nicely with this, albeit in a slightly counterintuitive way. Basically, during the search we ignore the fact that an <code class="highlighter-rouge">InvertibleReductionMemoizer[f]</code> has to actually choose a single value of <code class="highlighter-rouge">f</code>; we let everyone use the <code class="highlighter-rouge">reduce[f]</code> Impl without reservation. At the end of the search, we can figure out how many different instances of <code class="highlighter-rouge">InvertibleReductionMemoizer</code> we actually need: perhaps we need one for <code class="highlighter-rouge">getSum</code> and one for <code class="highlighter-rouge">getXor</code> or whatever other implementation we wanted to memoize. The number of instances of a data structure that we require only affects our write times by a constant multiple, so it’s irrelevant for the search we’re doing here.</p>

<p>The main other complexity is that the search needs to maintain its paths: we want to be able to know which data structures were used for which methods. This is maintained by storing this source information and passing it around with the implementations throughout.</p>

<h3 id="optimizations">Optimizations</h3>

<p>One obvious problem with this is that there are exponentially many potential composite data structures to look at. So I use some simple heuristics to cut down the number of composite data structures that I actually consider.</p>

<p>Firstly, data structures are only considered if they have a read method which could plausibly help with the implementation of one of the read methods in the ADT. “Could plausibly help” is determined by considering the directed graph formed by turning an Impl like <code class="highlighter-rouge">f &lt;- g + h</code> into the edges <code class="highlighter-rouge">g -&gt; f</code> and <code class="highlighter-rouge">h -&gt; f</code>–if there’s a path in that graph from <code class="highlighter-rouge">x</code> to <code class="highlighter-rouge">y</code>, a data structure providing <code class="highlighter-rouge">x</code> could plausibly help with an ADT requiring <code class="highlighter-rouge">y</code>. This usually cuts off half of the 15-or-so data structures I have, which makes things like 50 times faster. <a href="https://github.com/bshlgrs/data-structure-composer/blob/d18a104400e214e589cefb72f8d466b97ae44c5f/src/main/scala/implementationSearcher/ImplLibrary.scala#L55">This logic lives here.</a></p>

<p>Secondly, when searching through subsets, if I figure out method times for the set of data structures <script type="math/tex">\{A, B, C\}</script> and I’m considering looking at the set <script type="math/tex">\{A, B, C, D\}</script>, I look at whether any of the implementations provided by <script type="math/tex">D</script> are useful given the result of <script type="math/tex">\{A, B, C\}</script>. If not I don’t explore any subsets including all of <script type="math/tex">\{A, B, C, D\}</script>. <a href="https://github.com/bshlgrs/data-structure-composer/blob/d18a104400e214e589cefb72f8d466b97ae44c5f/src/main/scala/implementationSearcher/Searcher.scala#L118-L119">Here’s the source</a>. This makes things a few times faster.</p>

<p>I also cache results of calls to <code class="highlighter-rouge">getAllTimes</code>. If I’ve established that the read method <code class="highlighter-rouge">foo</code> takes <script type="math/tex">\log(n)</script> time for the set <script type="math/tex">\{A, B, C\}</script>, then I can immediately put the Impl <code class="highlighter-rouge">foo &lt;- log(n)</code> into the queue when running the search on <script type="math/tex">\{A, B, C, D\}</script>. I am not sure if this improves efficiency.</p>

<h2 id="deployment">Deployment</h2>

<p>The code is deployed as a Finagle server with a React app in front. The React app can display useful information about the internals of composite data structures.</p>

<p>I tried compiling my search code to ScalaJS, but it was too slow to be a pleasant experience. If my code was like 10x faster it would be alright.</p>

<h2 id="further-work">Further work</h2>

<p>Here are things I want to do:</p>

<ul>
  <li>Generate real code. The result already has all the information we need to generate code, I just haven’t put in the effort to make it work yet.</li>
  <li>Acquire users. I plan to use this to answer lots of questions on Quora etc, to get people to look at it, and hopefully people will start using it more regularly.</li>
  <li>Consider other optimizations. I added in a bunch of cruft in the final push before the conference presentation, and it’s possible that some refactoring might speed things up.</li>
  <li>Distinguish between different concepts like average case time, worst case time, and amortized time.</li>
  <li>Instead of minimizing asymptotic time, I could instead get an empirical measure of the speed of different methods in different data structures, and choose the fastest data structures for a given expected data set size using those measurements. This works best with the approach where we are generating real code with real data structure implementations.</li>
  <li>Extend to talk about other types of queries. In particular, I could try to support more SQL-style queries on multi-column data.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>How useful could a tool like this be? I don’t know. A lot of data structure research can’t yet be fit nicely into the framework of things I can describe with this system.</p>

<p>I also find that writing data structures down for this project forced me to think about them and write down facts about them that aren’t usually said. For example, the <a href="http://www.geeksforgeeks.org/range-minimum-query-for-static-array/">sparse table</a> data structure for <a href="https://en.wikipedia.org/wiki/Range_minimum_query">range minimum query</a> is usually not described as letting you push things on the end in amortized <script type="math/tex">O(\log(n))</script>, even though you can obviously do that by resizing exponentially. This forced clarity is really useful.</p>

<p>Overall the practical usefulness of this project remains to be seen. It was a lot of fun to build though.</p>

<p>Thanks heaps to everyone who helped me out as I was writing this.</p>

<h2 id="appendix-how-long-did-i-spend-on-this">Appendix: how long did I spend on this?</h2>

<p>According to RescueTime, I’ve spend 94 hours in IntelliJ this year. Almost all of that time was spent working on this project. A lot of the time I spent working on this project is not included in that number: the frontend was written using Sublime Text, and I had to spend a lot of time thinking in front of a whiteboard, and I spent the usual amount of time on StackOverflow or in a terminal.</p>

<p>My subjective experience is that I spent a bunch of time on this on most of my weekends and many of my evenings for the past two months. If I did on average four hours of work on each weekend day and ten hours of work over the week, that’s 14 hours a week times 8 weeks = 112 hours. I also took off two days from work to work entirely on this, and got about 8 hours done on each of those days.</p>

<p>When I feel like I am working on my software, I also often end up reading Facebook or whatever for 25% of the time. So the 94 hours I spent in IJ probably also involved spending an extra 30 on the internet.</p>

<p>My overall guess is that I spent between 150 and 200 hours on this project.</p>

  </section>
</div>



  </body>

<script>
if (window.location.hostname == "dfilan.github.io") {
  window.location.hostname = "shlegeris.com";
}
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52980069-1', 'auto');
  ga('send', 'pageview');

</script>



</html>

