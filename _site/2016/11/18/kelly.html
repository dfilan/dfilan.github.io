<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Kelly bettors</title>
  <meta name="description" content="The Kelly Criterion">


  <link rel="stylesheet" href="/stylesheets/styles.css">
  <link rel="stylesheet" href="/stylesheets/pygment_trac.css">
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  <link rel="canonical" href="http://localhost:4000/2016/11/18/kelly.html">
  <link rel="alternate" type="application/rss+xml" title="Daniel Filan" href="http://localhost:4000/feed.xml">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$$', '$$'] ],
        displayMath: [ ['$^$', '$^$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
  </script>
  <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>


  <body>

    

    <div class="wrapper">
  <header>
  <h1><a href="/">Daniel Filan</a></h1>
  <img src="/selfie.jpg"/>
  <ul>
    <li><a href="/posts">blog</a></li>
    <li><a href="mailto:df@danielfilan.com">email</a></li>
    <li><a href="/daniel_filan_public_key.asc">PGP public key</li>
    <li><a href="/pdfs/cv.pdf">CV</a></li>
    <li><a href="https://github.com/dfilan">github</a></li>
  </ul>
</header>


  <section>
    <h2>Kelly bettors</h2>
    <p class="post-meta"><time datetime="2016-11-18T00:00:00-08:00" itemprop="datePublished">Nov 18, 2016</time></p>
    <h3 id="the-kelly-criterion">The Kelly Criterion</h3>

<p>The Kelly criterion for betting tells you how much to wager when someone offers you a bet. First introduced in <a href="http://www.herrold.com/brokerage/kelly.pdf">this paper</a>, it deals with the situation where someone is offering you a contract that pays you €1 if the event <script type="math/tex">E</script> (for concreteness, you can imagine <script type="math/tex">E</script> as the event that the Republican candidate wins the 2020 US Presidential election) and €0 otherwise. They are selling it for €<script type="math/tex">q</script>, and your probability for <script type="math/tex">E</script> is <script type="math/tex">p > q</script> (this is equivalent to the more common formulation with odds, but it’s easier for me to think about). As a result, you think that it’s worth buying this contract. In fact, they will sell you a scaled-up contract of your choice: for any real number <script type="math/tex">r \geq 0</script>, you can buy a contract that pays you €<script type="math/tex">r/q</script> if <script type="math/tex">E</script> occurs for €<script type="math/tex">r</script>, just as if you could buy <script type="math/tex">r/q</script> copies of the original contract. The question you face is this: how much of your money should you spend on this scaled-up contract? The Kelly criterion gives you an answer: you should spend <script type="math/tex">(p-q)/(1-q)</script> of your money.</p>

<p>Why would you spend this exact amount? One reason would be if you were an expected utility maximiser, and your utility was the logarithm of your wealth. Note that the logarithm is important here to make you risk averse: if you simply wanted to maximise your expected wealth after the bet, you would bet all your money. To show that expected log-wealth maximisers use the Kelly criterion, note that if your initial wealth is <script type="math/tex">W</script>, you spend <script type="math/tex">fW</script> on the scaled contract, and <script type="math/tex">E</script> occurs, you then have <script type="math/tex">(1-f)W + fW/q</script>, while if you bet that much and <script type="math/tex">E</script> does not occur, your wealth is only <script type="math/tex">(1-f)W</script>. The expected log-wealth maximiser therefore wants to maximise</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} U &= p\log \left( (1-f)W + \frac{fW}{q} \right) + (1-p) \log ((1-f)W) \\ &= p \log \left(1 - f + \frac{f}{q} \right) + (1-p) \log (1-f) + \log (W)\text{.} \end{align} %]]></script>

<p>The derivative of this with respect to <script type="math/tex">f</script> is
$^$\frac{\partial U}{\partial f} = \left( \frac{p}{1-f + f/q} \right) \left( \frac{1}{q} - 1 \right) - \frac{1-p}{1-f}\text{.}$^$
Setting this derivative to 0 and rearranging produces the stated formula.</p>

<p>The <a href="https://en.wikipedia.org/w/index.php?title=Kelly_criterion&amp;oldid=742759833#Proof">Wikipedia page</a> as of 25 October 2016 gives another appealing fact about Kelly betting. Suppose that this contract-buying opportunity recurs again and again: that is, there are many events <script type="math/tex">E_t</script> in a row that you think each independently have probability <script type="math/tex">q</script>, and after your contract about <script type="math/tex">E_{t-1}</script> resolves, you can always spend €<script type="math/tex">r</script> on a contract that will pay €<script type="math/tex">r/p</script> if <script type="math/tex">E_t</script> happens. Suppose that you always spend <script type="math/tex">f</script> of your wealth on these contracts, you make <script type="math/tex">N</script> of these bets, and <script type="math/tex">K</script> pay off. Then, your final wealth after the <script type="math/tex">N</script> bets will be
$^$\text{Wealth} = \left(1-f+\frac{f}{q} \right)^K (1-f)^{N-K} W \text{.}$^$
The derivative of this with respect to <script type="math/tex">f</script> is</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align} \frac{\partial \text{Wealth}}{\partial f} &= W\left( K \left(1-f+ \frac{f}{q} \right)^{K-1} \left(\frac{1}{q} - 1 \right)(1-f)^{N-K} \right. \\ &\quad \left. {} - \left(1-f+ \frac{f}{q} \right)^K (N-K)(1-f)^{N-K-1}\right) \text{.} \end{align} %]]></script>

<p>Setting this to 0 gives <script type="math/tex">f = K/N - ((N-K)/N)(q/(1-q))</script>, and if <script type="math/tex">K/N = p</script> (which it should in the long run), this simplifies to <script type="math/tex">f = (p-q)/(1-q)</script>, the Kelly criterion. This makes it look like Kelly betting maximises your total wealth after the <script type="math/tex">N</script> runs, so why wouldn’t an expected wealth maximiser use the Kelly criterion? Well, the rule of betting all your money every chance you have leaves you with nothing if <script type="math/tex">K = pN</script>, but in the unlikely case that <script type="math/tex">K = N</script>, the rule works out so well that expected wealth maximisers think that it’s worth the risk.</p>

<p>Before I move on, I’d like to share one interesting fact about the Kelly criterion that gives a flavour of the later results. You might wonder what the expected utility of using the Kelly criterion is. Well, by simple substitution it’s just <script type="math/tex">p \log (p/q) + (1-p) \log ((1-p)/(1-q)) + \log (W)</script>. Ignoring the <script type="math/tex">\log (W)</script> utility that you already have, this is just <span><script type="math/tex">D_{KL}(p||q)</script></span>. Bam! <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Information theory!</a></p>

<h3 id="kelly-bettors-in-prediction-markets">Kelly bettors in prediction markets</h3>

<p>Previously, we talked about the case where somebody was offering to sell you a contract at a fixed price, and all you could do was keep it. Instead, we can consider a market full of these contracts, where all of the participants are log wealth maximisers, and think about what the equilibrium price is. Our proof will be similar to the one found <a href="https://arxiv.org/pdf/1201.6655.pdf">here</a>.</p>

<p>Before diving into the math, let’s clarify exactly what sort of situation we’re imagining. First of all, there are going to be lots of contracts available that correspond to different outcomes in the same event, at least one of which will occur. For instance, the event could be “Who will win the Democratic nomination for president in 2020?”, and the outcomes could be “Cory Booker”, “Elizabeth Warren”, “Martin O’Malley”, and all the other candidates (once they are known - before then, the outcomes could be each member of a list of prominent Democrats and one other outcome corresponding to “someone else”). Alternatively, the event could be “What will the map of winners of each state in the 2020 presidential election be?”, and the outcomes would be lists of the form “Republicans win Alabama, Democrats win Alaska, Democrats win Arizona, …”. This latter type of market actually forms a <a href="http://blog.oddhead.com/2008/12/22/what-is-and-what-good-is-a-combinatorial-prediction-market/">combinatorial prediction market</a> – by buying and short-selling bundles of contracts, you can make bets of the form “Republicans will win Georgia”, “If Democrats win Ohio, then Republicans will win Florida”, or “Republicans will win either North Dakota or South Dakota, but not both”. Such markets are interesting for their own reasons, but we will not elaborate on them here.</p>

<p>We should also clarify our assumptions about the traders. The participants are log wealth maximisers who have different priors and don’t think that the other participants know anything that they don’t – otherwise, the <a href="https://en.wikipedia.org/wiki/No-trade_theorem">no-trade theorem</a> could apply. We also assume that they are <a href="http://www.investopedia.com/terms/p/pricetaker.asp">price takers</a>, who decide to buy or sell contracts at whatever the equilibrium price is, not considering how their trades effect the equilibrium price.</p>

<p>Now that we know the market setup, we can derive the purchasing behaviour of the participants for a given market price. We will index market participants by <script type="math/tex">i</script> and outcomes by <script type="math/tex">j</script>. We write <script type="math/tex">q_j</script> for the market price of the contract that pays €1 if outcome <script type="math/tex">j</script> occurs, <script type="math/tex">p^i_j</script> for the probability that participant <script type="math/tex">i</script> assigns to outcome <script type="math/tex">j</script>, and <script type="math/tex">W^i</script> for the initial wealth of participant <script type="math/tex">i</script>.</p>

<p>First of all, without loss of generality, we can assume that participant <script type="math/tex">i</script> spends all of their wealth on contracts. This is because if they spend some money on all contracts, they are guaranteed some payoff, just as if they had saved some money. We can therefore write the amount that participant <script type="math/tex">i</script> spends on contracts for outcome <script type="math/tex">j</script> as <script type="math/tex">W^i \tilde{p}^i_j</script>, under the condition that <script type="math/tex">\sum_j \tilde{p}^i_j = 1</script>. Then, if outcome <script type="math/tex">j</script> occurs, their posterior wealth will be <script type="math/tex">W^i \tilde{p}^i_j / q_j</script>. We can use the method of Lagrange multipliers to determine how much participant <script type="math/tex">i</script> will bet on each outcome, by maximising
$^$L(\tilde{p}^i, \lambda) = \sum_j p^i_j \log \left(\frac{W^i \tilde{p}^i_j}{q_j}\right) - \lambda \left( \sum_j \tilde{p}^i_j - 1\right)\text{.}$^$
Taking partial derivatives,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}\frac{\partial L}{\partial \tilde{p}^i_j} &= \frac{p^i_j}{\tilde{p}^i_j} - \lambda \\ &= 0\text{,}\end{align} %]]></script>

<p>so <script type="math/tex">\tilde{p}^i_j = p^i_j / \lambda</script>, and</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}\frac{\partial L}{\partial \lambda} &= \sum_j \tilde{p}^i_j - 1 \\ & = 0\text{,}\end{align} %]]></script>

<p>so <script type="math/tex">\lambda^{-1} \sum_j p^i_j = 1</script>, so <script type="math/tex">\lambda = 1</script>. Therefore, regardless of the market prices, participant <script type="math/tex">i</script> will spend <script type="math/tex">W^i p^i_j</script> on contracts for outcome <script type="math/tex">j</script>. You might notice that this looks different to the previous section – this is because previously our bettor could only bet on one outcome, as opposed to betting on both.</p>

<p>Next, we can generalise to the case where the market participants save some amount of money, buy some contracts, and sell some others. This will be important for deriving the equilibrium market behaviour, since you can’t have a market where everyone wants to buy contracts and nobody wants to sell them.</p>

<p>Suppose trader <script type="math/tex">i</script> saves <script type="math/tex">W^i s^i</script> and spends <script type="math/tex">W^i \tilde{p}^i_j</script> on contracts for each outcome <script type="math/tex">j</script>. Here, we allow <script type="math/tex">\tilde{p}^i_j</script> to be negative - this means that <script type="math/tex">i</script> will sell another trader <script type="math/tex">-W^i \tilde{p}^i_j</script> worth of contracts, and will supply that trader with <script type="math/tex">-W^i \tilde{p}^i_j/q_j</script> if outcome <script type="math/tex">j</script> occurs. We now demand that <script type="math/tex">s^i + \sum_j \tilde{p}^i_j = 1</script> for <script type="math/tex">s_i</script> to make sense. Now, if outcome <script type="math/tex">j</script> occurs, trader <script type="math/tex">i</script>’s wealth will be <script type="math/tex">W^i(s^i + \tilde{p}^i_j/q_j)</script> – if <script type="math/tex">\tilde{p}^i_j > 0</script> then the trader makes money off their contracts in outcome <script type="math/tex">j</script>, and if <script type="math/tex">% <![CDATA[
\tilde{p}^i_j < 0 %]]></script> then the trader pays their dues to the holder of the contract in outcome <script type="math/tex">j</script> they sold. We’d like this to be equal to <script type="math/tex">W^i p^i_j/q_j</script>, so that the trader’s wealth is the same as if they had saved all their money. This happens if <script type="math/tex">s^i + \tilde{p}^i_j/q_j = p^i_j/q_j</script>, i.e. <script type="math/tex">\tilde{p}^i_j = p^i_j - s^i q_j</script>.</p>

<p>Now that we have the behaviour of each trader for a fixed market price, we can derive the equilibrium prices of the market. At equilibrium, supply should be equal to demand, meaning that there are as many contracts being bought as being sold: for all <script type="math/tex">j</script>, <script type="math/tex">\sum_i W^i \tilde{p}^i_j = 0</script>. This implies that <script type="math/tex">\sum_i W^i (p^i_j - s^i q_j) = 0</script>, or <script type="math/tex">q_j = \left( \sum_i W^i p^i_j \right)/\left( \sum_i W^i s^i \right)</script>. It must also be the case that <script type="math/tex">\sum_j q_j = 1</script>, since otherwise the agents could arbitrage, putting pressure on the prices to satisfy <script type="math/tex">\sum_j q_j = 1</script>. This means that <script type="math/tex">\sum_j \left(\sum_i W^i p^i_j\right)/\left(\sum_i W^i s^i\right) = 1</script>, implying that <script type="math/tex">\sum_i W^i = \sum_i W^i s^i</script> and <script type="math/tex">q_j = \sum_i W^i p^i_j / \left(\sum_i W^i\right)</script>.</p>

<p>Note the significance of this price: it’s as if we have a Bayesian mixture where each trader corresponds to a hypothesis, our prior in hypothesis <script type="math/tex">i</script> is <script type="math/tex">h^i = W^i / \left(\sum_i W^i\right)</script>, and the market price is the Bayesian mixture probability <script type="math/tex">\sum_i h^i p^i_j</script>. How much wealth does the participant/hypothesis have after we know the outcome? Exactly <script type="math/tex">W_i p^i_j \left(\sum_i W^i\right) / \left(\sum_i W^i p^i_j\right) = \left(\sum_i W_i\right) h^i p^i_j / \left(\sum_i h^i p^i_j\right)</script>, proportional to the posterior probability of that hypothesis. Our market has done an excellent job of replicating a Bayesian mixture!</p>

<h3 id="but-is-it-general-enough">But is it general enough?</h3>

<p>You might have thought that the above discussion was sufficiently general, but you’d be wrong. It only applies to markets with a countable number of possible outcomes. Suppose instead that we’re watching someone throw a dart at a dartboard, and will be able to see the exact point where the dart will land. In general, we imagine that there’s a set <script type="math/tex">\Omega</script> (the dartboard) of outcomes <script type="math/tex">\omega</script> (points on the dartboard), and you have a probability distribution <script type="math/tex">P</script> that assigns probability to any event <script type="math/tex">E \subseteq \Omega</script> (region of the dartboard). (More technically, <script type="math/tex">\Omega</script> will be a measurable set with sigma-algebra <script type="math/tex">\mathcal{F}</script> which all our subsets will belong to, <script type="math/tex">P</script> will be a probability measure, and all functions mentioned will be measurable.)</p>

<p>First, let’s imagine that there’s just one agent with wealth <script type="math/tex">W</script> and probability distribution <script type="math/tex">P</script>, betting against the house which has probability distribution <script type="math/tex">Q</script>. This agent can buy some number <script type="math/tex">b(\omega)</script> of contracts from the house that each pay €1 if <script type="math/tex">\omega</script> occurs and €0 otherwise, for every <script type="math/tex">\omega \in \Omega</script> (similarly to the previous section, if <script type="math/tex">% <![CDATA[
b(\omega) < 0 %]]></script> the agent is selling these contracts to the house). The house charges the agent the expected value of their bets: <script type="math/tex">\mathbb{E}_{Q} [b(\omega)]</script>. The question: what function <script type="math/tex">b</script> should the agent choose to bet with?</p>

<p>Our agent is an expected log wealth maximiser, so they want to choose <script type="math/tex">b</script> to maximise <script type="math/tex">\mathbb{E}_{P} [\log b(\omega)]</script>. However, they are constrained by only betting as much money as they have (and without loss of generality, exactly as much money as they have). Therefore, the problem is to optimise the Lagrangian</p>

<p><span><script type="math/tex">% <![CDATA[
\begin{align} L(b, \lambda) &= \mathbb{E}_{P}  [ \log b(\omega) ]  - \lambda \left( W - \mathbb{E}_Q  [ b(\omega) ] \right) \\ &= \mathbb{E}_{P}  [ \log b(\omega) ] - \mathbb{E}_Q[\lambda(W - b(\omega))] \end{align} %]]></script></span></p>

<p>To make this easier to manipulate, we’re going to want to make all of this an expectation with respect to <script type="math/tex">Q</script>, using an object <script type="math/tex">dP/dQ (\omega)</script> called the <a href="https://en.wikipedia.org/wiki/Radon%E2%80%93Nikodym_theorem">Radon-Nikodym derivative</a>. Essentially, if we were thinking about <script type="math/tex">\omega</script> as being a point on a dartboard, we could think of the probability density functions <script type="math/tex">p(\omega)</script> and <script type="math/tex">q(\omega)</script>, and it would be the case that <span><script type="math/tex">\mathbb{E}_{P}[f(\omega)] = \mathbb{E}_{Q} [f(\omega) p(\omega) / q(\omega)]</script></span>. The Radon-Nikodym derivative acts just like the factor <script type="math/tex">p(\omega) / q(\omega)</script>, and is always defined as long as whenever <script type="math/tex">Q</script> assigns some set probability 0, <script type="math/tex">P</script> does as well (otherwise, you should imagine that <script type="math/tex">q(\omega) = 0</script> so <script type="math/tex">p(\omega) / q(\omega)</script> isn’t defined). This lets us rewrite the Lagrangian as</p>

<p><span>$^$ L(b, \lambda) = \mathbb{E}_{Q}  \left[ \left( \log b(\omega) \right) \frac{dP}{dQ}(\omega) - \lambda(W - b(\omega)) \right] $^$</span></p>

<p>We have one more trick up our sleeves to maximise this with respect to <script type="math/tex">b</script>. At a maximum, changing <script type="math/tex">b</script> to <script type="math/tex">b + \delta b</script> should only change <script type="math/tex">L</script> up to second order, for any small <script type="math/tex">\delta b</script>. So,</p>

<p><span><script type="math/tex">% <![CDATA[
\begin{align}L(b + \delta b, \lambda) &= \mathbb{E}_{Q}  \left[ \left( \log (b(\omega) + \delta b(\omega))  \right) \frac{dP}{dQ}(\omega) - \lambda(W - b(\omega) - \delta b(\omega)) \right] \\ &= \mathbb{E}_{Q} \left[ \left( \log b(\omega) + \frac{\delta b(\omega)}{b(\omega)} \right) \frac{dP}{dQ}(\omega) - \lambda (W - b(\omega) - \delta b(\omega))\right] \\
&\quad {} + o(\delta b(\omega)^2)\\
&= L(b, \lambda) + \mathbb{E}_Q \left[ \frac{\delta b(\omega)}{b(\omega)} \frac{dP}{dQ}(\omega) + \lambda \delta b(\omega)\right] + o(\delta b(\omega)^2)\end{align} %]]></script></span></p>

<p>We therefore require that <script type="math/tex">\mathbb{E}_Q [(\delta b(\omega) / b(\omega)) (dP/dQ(\omega)) + \lambda \delta b(\omega)] = 0</script> for all <script type="math/tex">\delta b(\omega)</script>. This can only happen when <script type="math/tex">b(\omega) = - \lambda^{-1} dP/dQ(\omega)</script>, and it’s easy to check that we need <script type="math/tex">\lambda = -W^{-1}</script>. Therefore, the agent buys <script type="math/tex">W \times dP/dQ(\omega)</script> shares in outcome <script type="math/tex">\omega</script>, which you should be able to check is the same as in the case of countably many contracts.</p>

<p>Suppose we want to express the bet equivalently as our agent saving <script type="math/tex">S</script>. For this to be equivalent to the agent spending all their money, we need <script type="math/tex">b(\omega) + S = W \times dP/dQ(\omega)</script> for all <script type="math/tex">\omega</script>, which is easily solved.</p>

<p>Now, suppose we’re in a market with many agents, indexed by <script type="math/tex">i</script>. Each agent has wealth <script type="math/tex">W^i</script>, probabilities <script type="math/tex">P^i</script>, and saves <script type="math/tex">S^i</script>. In response to a market probability <script type="math/tex">Q</script>, they buy <script type="math/tex">W^i dP^i/dQ(\omega) - S^i</script> contracts for outcome <script type="math/tex">\omega</script>. What is this equilibrium market probability?</p>

<p>We would like to think of markets for each outcome <script type="math/tex">\omega</script> and solve for equilibrium, but it could be that each agent assigns probability 0 to every outcome. For instance, if I’m throwing a dart at a dartboard, and your probability that I hit some region is proportional to the area of the region, then for any particular point your probability that I will hit that point is 0. If this is the case, then the equilibrium price for contracts in every outcome will be 0, which tells us nothing about how traders buy and sell these contracts. Instead, we’ll imagine that there’s a set of events <script type="math/tex">\{ E_j \}</script> that are mutually exclusive with the property that one of them is sure to happen – in the case of the dartboard, this would be a collection of regions that don’t overlap and cover the whole dartboard. The agents will bundle all of their contracts for outcomes of the same event, and buy and sell those together. In this case, letting <span><script type="math/tex">[[ \omega \in E]]</script></span> be the <a href="https://en.wikipedia.org/wiki/Iverson_bracket">function</a> that is 1 if <script type="math/tex">\omega \in E</script> and 0 otherwise, the condition for equilibrium is</p>

<p><span><script type="math/tex">% <![CDATA[
\begin{align} 0 &= \sum_i \mathbb{E}_Q \left[ [[\omega \in E_j]] \left(  W^i \frac{dP^i}{dQ}(\omega) - S^i \right)\right] \\
\sum_i W^i P^i (E_j) &= Q(E_j) \left( \sum_i S^i \right) \end{align} %]]></script></span></p>

<p>To avoid arbitrage, it must be the case that <script type="math/tex">\sum_i S^i = \sum_i W^i</script>, therefore we require that for all <script type="math/tex">j</script>, <span><script type="math/tex">Q(E_j) = \sum_i W^i P^i (E_j) / \left( \sum_i W^i \right)</script></span>. Now, in the limit of there being infinitely many infinitely small sets <script type="math/tex">E_j</script>, all sets are just a union of some of the sets <script type="math/tex">E_j</script>, and in general we will have <script type="math/tex">Q(E) = \sum_i W^i P^i(E) / \left( \sum_i W^i \right)</script>. This is just like the discrete case: our market prices are exactly Bayes mixture probabilities, and as a result the wealth of each agent after the bets are paid will be proportional to their posterior credence in the mixture.</p>

<p>Finally, it’s worth noting something interesting that’s perhaps more obvious in this formalism than in others. Suppose we again have a single agent betting on which outcome would occur with the house, but instead of learning the outcome <script type="math/tex">\omega</script>, the house and agent only learn that the outcome was in some event <script type="math/tex">E</script>. In this case, the agent would have spent <span><script type="math/tex">\mathbb{E}_Q [W \times dP/dQ(\omega)  [[\omega \in E]] ] = W P(E)</script></span> on contracts for outcomes in <script type="math/tex">E</script>, and should presumably be paid the house’s posterior expected value of those contracts:
<span>$^$ \frac{\mathbb{E}_Q [W \times dP/dQ(\omega) [[\omega \in E]] ]}{Q(E)} = W \frac{P(E)}{Q(E)} $^$</span>
Now, this is exactly what would have happened if the agent had been asked which of events <script type="math/tex">E_1</script> through <script type="math/tex">E_n</script> would occur: the agent would bet <script type="math/tex">W P(E_i)</script> on each event <script type="math/tex">E_i</script> and in the case that event <script type="math/tex">E_j</script> occurred, would be paid <script type="math/tex">W P(E_j)/ Q(E_j)</script>. In the dartboard example, instead of learning which point the dart would land on, you only learned how many points the throw was worth and your bets only paid out accordingly, but it turned out that you bet optimally anyway, despite the payouts being different to what you thought they were. Therefore, Kelly betting has this nice property that you don’t need to know exactly what you’re betting on: as long as you know the space of possible outcomes, you’ll bet optimally no matter what the question about the outcomes is.</p>

  </section>
</div>



  </body>

<script>
if (window.location.hostname == "dfilan.github.io") {
  window.location.hostname = "shlegeris.com";
}
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52980069-1', 'auto');
  ga('send', 'pageview');

</script>



</html>

